{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5f4d91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import jaccard_score\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6994e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cfbce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "os.makedirs(os.path.join(os.path.expanduser(\"~\"), \".kaggle\"), exist_ok=True)\n",
    "with open(os.path.join(os.path.expanduser(\"~\"), \".kaggle\", \"kaggle.json\"), \"w\") as f:\n",
    "    json.dump({\"username\":\"username\",\"key\":\"apikey\"}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "475d9fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The syntax of the command is incorrect.\n"
     ]
    }
   ],
   "source": [
    "!mkdir ~/.kaggle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2387d13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'--chmod' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!--chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8be2075",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n"
     ]
    }
   ],
   "source": [
    "!cd ~/.kaggle/ && ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d5ae87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KAGGLE_USERNAME\"] = \"pacymugisho\"\n",
    "os.environ[\"KAGGLE_KEY\"] = \"a526600c8b9968cc980d6db82fe706f1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5be8e3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref                                                  title                                           size  lastUpdated                 downloadCount  voteCount  usabilityRating  \n",
      "---------------------------------------------------  ---------------------------------------  -----------  --------------------------  -------------  ---------  ---------------  \n",
      "shuvoalok/cityscapes                                 cityscapes dataset                         209001313  2023-09-13 21:03:34.607000           5999         25  0.875            \n",
      "balraj98/cityscapes-pix2pix-dataset                  Cityscapes Pix2Pix Dataset                 105595335  2020-10-18 08:10:17.600000            767         17  0.9411765        \n",
      "vikramtiwari/pix2pix-dataset                         pix2pix dataset                           2574957257  2018-07-04 05:54:59.713000           8826        114  0.625            \n",
      "dansbecker/cityscapes-image-pairs                    Cityscapes Image Pairs                     211492512  2018-04-20 13:55:20.627000          18480        264  0.75             \n",
      "yessicatuteja/foggy-cityscapes-image-dataset         Foggy Cityscapes Images                   3171746124  2024-02-18 09:27:16.383000           1330         36  1                \n",
      "sakshaymahna/cityscapes-depth-and-segmentation       CityScapes - Depth and Segmentation        673063205  2021-12-04 09:08:13.817000           2368         26  0.625            \n",
      "preetviradiya/cityscapes-dataset-for-gans            Cityscapes dataset for GANs                280287193  2022-02-15 05:10:46.123000            196          9  0.375            \n",
      "ishansrivastava1308/image-map-cityscapes-19510       CityScapes Dataset                       11848210160  2024-06-08 03:29:53.660000             10          1  0.4375           \n",
      "kareemmetwaly/cityscapes-attributes-recognition-car  Cityscapes Attributes Recognition (CAR)        23911  2025-12-07 10:45:55.370000             83         19  0.6875           \n",
      "norod78/sketch2pokemon                               Sketch2Pokemon                             137519017  2019-10-28 09:09:41.103000            490         10  0.8125           \n",
      "sakshaymahna/semantic-segmentation-bev               Semantic Segmentation - BEV               2155380825  2025-12-10 15:47:30.667000            479         22  0.875            \n",
      "hungngu1999/cityscapes-dataset                       Cityscapes dataset                       11848107556  2022-02-17 12:46:12.643000             61          2  0.125            \n",
      "zhangyunsheng/cityscapes-data                        cityscapes_data                            105579467  2020-06-18 07:11:17.440000            937          9  0.6875           \n",
      "utkarshsaxenadn/cityscapessegmentationpix2pixgan     Cityscapes-Segmentation-Pix2PixGAN         201741577  2022-09-13 10:05:09.577000           1271          9  0.9375           \n",
      "zeadomar/geoeye-70-earth-observation                 GEOEYE-70 | Earth Observation             1277327461  2024-04-04 12:07:56.150000             80          7  0.625            \n",
      "peopledream/cityscapes-dataset                       Cityscapes dataset                         856629887  2024-01-20 12:36:20.320000             17          0  0.375            \n",
      "shaniasalsabillaq/cityscapes-dataset                 Cityscapes Dataset                         125672299  2024-07-23 14:39:14.880000              1          0  0.375            \n",
      "manjotpahwa/indian-driving-dataset                   Indian Driving Dataset                    5920724657  2019-11-17 13:37:55.133000           1092         14  0.4375           \n",
      "felixjfj/cityscapes-augmented                        cityscapes_augmented                     44391420830  2025-01-15 17:22:17.203000              9          1  0.6875           \n",
      "beyondstellaris/bluegreen-algae-dataset              Blue-green algae dataset                  2468240161  2022-10-15 07:23:42.603000            275          7  0.375            \n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets list -s \"cityscapes dataset\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14a89ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\DELL\\.cache\\kagglehub\\datasets\\shuvoalok\\cityscapes\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"shuvoalok/cityscapes\")\n",
    "\n",
    "print(\"Path to dataset files:\", path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee92d0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "train_images_folder_path = \"/kaggle/input/cityscapes/train/img\"\n",
    "train_mask_folder_path = \"/kaggle/input/cityscapes/train/label\"\n",
    "test_images_folder_path = \"/kaggle/input/cityscapes/val/img\"\n",
    "test_mask_folder_path = \"/kaggle/input/cityscapes/val/label\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e51719a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CONSTANTS ==========\n",
    "names = ['unlabeled', 'dynamic', 'ground', 'road', 'sidewalk', 'parking', 'rail track', 'building', 'wall',\n",
    "         'fence', 'guard rail', 'bridge', 'tunnel', 'pole', 'traffic light', 'traffic sign', 'vegetation', \n",
    "         'terrain', 'sky', 'person', 'rider', 'car', 'truck', 'bus', 'caravan', 'trailer', 'train', \n",
    "         'motorcycle', 'bicycle', 'license plate']\n",
    "\n",
    "colors = np.array([\n",
    "    (0, 0, 0), (111, 74, 0), (81, 0, 81), (128, 64, 128), (244, 35, 232), \n",
    "    (250, 170, 160), (230, 150, 140), (70, 70, 70), (102, 102, 156), \n",
    "    (190, 153, 153), (180, 165, 180), (150, 100, 100), (150, 120, 90), \n",
    "    (153, 153, 153), (250, 170, 30), (220, 220, 0), (107, 142, 35), \n",
    "    (152, 251, 152), (70, 130, 180), (220, 20, 60), (255, 0, 0), \n",
    "    (0, 0, 142), (0, 0, 70), (0, 60, 100), (0, 0, 90), (0, 0, 110), \n",
    "    (0, 80, 100), (0, 0, 230), (119, 11, 32), (0, 0, 142)\n",
    "], dtype=np.uint8)\n",
    "\n",
    "IMG_HEIGHT, IMG_WIDTH = 96, 256\n",
    "NUM_CLASSES = 30\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5790dc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "==================================================\n",
      "STARTING TRAINING WITH SEED 0\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/kaggle/input/cityscapes/train/img'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 547\u001b[39m\n\u001b[32m    545\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, seed \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(seeds):\n\u001b[32m    546\u001b[39m     save_dir = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m./Good_train/1_gdn/Train_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m547\u001b[39m     model, history, test_iou, test_acc = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    549\u001b[39m     results.append({\n\u001b[32m    550\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m'\u001b[39m: seed,\n\u001b[32m    551\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mtest_iou\u001b[39m\u001b[33m'\u001b[39m: test_iou,\n\u001b[32m    552\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mtest_acc\u001b[39m\u001b[33m'\u001b[39m: test_acc,\n\u001b[32m    553\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mbest_val_iou\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mmax\u001b[39m(history[\u001b[33m'\u001b[39m\u001b[33mval_iou\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    554\u001b[39m     })\n\u001b[32m    556\u001b[39m \u001b[38;5;66;03m# Print summary\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 271\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(seed, save_dir)\u001b[39m\n\u001b[32m    268\u001b[39m os.makedirs(save_dir, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    270\u001b[39m \u001b[38;5;66;03m# Get file lists\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m271\u001b[39m train_images_names = \u001b[38;5;28msorted\u001b[39m([f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images_folder_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m f.endswith(\u001b[33m'\u001b[39m\u001b[33m.png\u001b[39m\u001b[33m'\u001b[39m)])\n\u001b[32m    272\u001b[39m train_mask_names = \u001b[38;5;28msorted\u001b[39m([f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os.listdir(train_mask_folder_path) \u001b[38;5;28;01mif\u001b[39;00m f.endswith(\u001b[33m'\u001b[39m\u001b[33m.png\u001b[39m\u001b[33m'\u001b[39m)])\n\u001b[32m    273\u001b[39m test_images_names = \u001b[38;5;28msorted\u001b[39m([f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os.listdir(test_images_folder_path) \u001b[38;5;28;01mif\u001b[39;00m f.endswith(\u001b[33m'\u001b[39m\u001b[33m.png\u001b[39m\u001b[33m'\u001b[39m)])\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] The system cannot find the path specified: '/kaggle/input/cityscapes/train/img'"
     ]
    }
   ],
   "source": [
    "# ========== GDN LAYER ==========\n",
    "class NonNegConstraint:\n",
    "    def __call__(self, tensor):\n",
    "        return torch.clamp(tensor, min=1e-15)\n",
    "\n",
    "class GDN(nn.Module):\n",
    "    def __init__(self, in_channels, filter_size=3):\n",
    "        super(GDN, self).__init__()\n",
    "        self.filter_size = filter_size\n",
    "        self.padding = (filter_size - 1) // 2\n",
    "        \n",
    "        # Parameters\n",
    "        self.beta = nn.Parameter(torch.ones(in_channels))\n",
    "        self.alpha = nn.Parameter(torch.ones(in_channels), requires_grad=False)\n",
    "        self.epsilon = nn.Parameter(torch.ones(in_channels), requires_grad=False)\n",
    "        \n",
    "        # Gamma weights (constrained to be non-negative)\n",
    "        self.gamma = nn.Parameter(torch.zeros(filter_size, filter_size, in_channels, in_channels))\n",
    "        \n",
    "        # Apply constraints\n",
    "        self.constraint = NonNegConstraint()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply constraints\n",
    "        with torch.no_grad():\n",
    "            self.beta.data = self.constraint(self.beta.data)\n",
    "            self.alpha.data = self.constraint(self.alpha.data)\n",
    "            self.epsilon.data = self.constraint(self.epsilon.data)\n",
    "            self.gamma.data = self.constraint(self.gamma.data)\n",
    "        \n",
    "        # Compute normalization\n",
    "        abs_x = torch.abs(x)\n",
    "        norm_conv = F.conv2d(\n",
    "            abs_x ** self.alpha.view(1, -1, 1, 1),\n",
    "            self.gamma.permute(3, 2, 0, 1),  # [out_c, in_c, h, w]\n",
    "            padding=self.padding,\n",
    "            groups=self.gamma.shape[3]  # Depthwise convolution\n",
    "        )\n",
    "        \n",
    "        norm = self.beta.view(1, -1, 1, 1) + norm_conv\n",
    "        norm = norm ** self.epsilon.view(1, -1, 1, 1)\n",
    "        \n",
    "        return x / norm\n",
    "\n",
    "# ========== DATASET ==========\n",
    "class CityscapesDataset(Dataset):\n",
    "    def __init__(self, image_folder, mask_folder, image_names, mask_names, \n",
    "                 height=IMG_HEIGHT, width=IMG_WIDTH, transform=None, is_train=True):\n",
    "        self.image_folder = image_folder\n",
    "        self.mask_folder = mask_folder\n",
    "        self.image_names = image_names\n",
    "        self.mask_names = mask_names\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = os.path.join(self.image_folder, self.image_names[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Load mask\n",
    "        mask_path = os.path.join(self.mask_folder, self.mask_names[idx])\n",
    "        mask = Image.open(mask_path).convert('RGB')\n",
    "        \n",
    "        # Resize\n",
    "        image = image.resize((self.width, self.height), Image.BILINEAR)\n",
    "        mask = mask.resize((self.width, self.height), Image.NEAREST)\n",
    "        \n",
    "        # Convert to numpy arrays\n",
    "        image = np.array(image).astype(np.float32) / 255.0\n",
    "        mask = np.array(mask).astype(np.int32)\n",
    "        \n",
    "        # One-hot encode mask\n",
    "        one_hot_mask = np.zeros((self.height, self.width, NUM_CLASSES), dtype=np.float32)\n",
    "        for i, color in enumerate(colors):\n",
    "            class_map = np.all(mask == color, axis=-1)\n",
    "            one_hot_mask[:, :, i] = class_map\n",
    "        \n",
    "        # Convert to tensors\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1)  # [C, H, W]\n",
    "        one_hot_mask = torch.from_numpy(one_hot_mask).permute(2, 0, 1)  # [C, H, W]\n",
    "        \n",
    "        return image, one_hot_mask\n",
    "\n",
    "# ========== MODEL ==========\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, pool=True, dropout=0.2):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.pool = pool\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.dropout1 = nn.Dropout2d(dropout)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.dropout2 = nn.Dropout2d(dropout)\n",
    "        \n",
    "        if pool:\n",
    "            self.pool_layer = nn.MaxPool2d(2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        if self.pool:\n",
    "            return x, self.pool_layer(x)\n",
    "        return x\n",
    "\n",
    "class UNetGDN(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=NUM_CLASSES):\n",
    "        super(UNetGDN, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.gdn = GDN(in_channels)\n",
    "        self.enc1 = ConvBlock(in_channels, 16, pool=True)\n",
    "        self.enc2 = ConvBlock(16, 32, pool=True)\n",
    "        self.enc3 = ConvBlock(32, 64, pool=True)\n",
    "        self.enc4 = ConvBlock(64, 128, pool=True)\n",
    "        \n",
    "        # Bridge\n",
    "        self.bridge = ConvBlock(128, 256, pool=False)\n",
    "        \n",
    "        # Decoder\n",
    "        self.up1 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec1 = ConvBlock(256, 128, pool=False)\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec2 = ConvBlock(128, 64, pool=False)\n",
    "        \n",
    "        self.up3 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
    "        self.dec3 = ConvBlock(64, 32, pool=False)\n",
    "        \n",
    "        self.up4 = nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2)\n",
    "        self.dec4 = ConvBlock(32, 16, pool=False)\n",
    "        \n",
    "        # Output\n",
    "        self.out_conv = nn.Conv2d(16, num_classes, 1)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        g1 = self.gdn(x)\n",
    "        x1, p1 = self.enc1(g1)\n",
    "        x2, p2 = self.enc2(p1)\n",
    "        x3, p3 = self.enc3(p2)\n",
    "        x4, p4 = self.enc4(p3)\n",
    "        \n",
    "        # Bridge\n",
    "        b1 = self.bridge(p4)\n",
    "        \n",
    "        # Decoder\n",
    "        u1 = self.up1(b1)\n",
    "        c1 = torch.cat([u1, x4], dim=1)\n",
    "        x5 = self.dec1(c1)\n",
    "        \n",
    "        u2 = self.up2(x5)\n",
    "        c2 = torch.cat([u2, x3], dim=1)\n",
    "        x6 = self.dec2(c2)\n",
    "        \n",
    "        u3 = self.up3(x6)\n",
    "        c3 = torch.cat([u3, x2], dim=1)\n",
    "        x7 = self.dec3(c3)\n",
    "        \n",
    "        u4 = self.up4(x7)\n",
    "        c4 = torch.cat([u4, x1], dim=1)\n",
    "        x8 = self.dec4(c4)\n",
    "        \n",
    "        # Output\n",
    "        out = self.out_conv(x8)\n",
    "        return self.softmax(out)\n",
    "\n",
    "# ========== METRICS ==========\n",
    "def iou_metrics(y_true, y_pred, num_classes=NUM_CLASSES):\n",
    "    \"\"\"Calculate mean IoU\"\"\"\n",
    "    ious = []\n",
    "    batch_size = y_true.shape[0]\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        # Flatten predictions and ground truth\n",
    "        pred_flat = y_pred[i].reshape(-1).cpu().numpy()\n",
    "        true_flat = torch.argmax(y_true[i], dim=0).reshape(-1).cpu().numpy()\n",
    "        \n",
    "        # Calculate IoU for each class\n",
    "        iou = jaccard_score(true_flat, pred_flat, \n",
    "                           average='macro', \n",
    "                           labels=np.arange(num_classes),\n",
    "                           zero_division=0)\n",
    "        ious.append(iou)\n",
    "    \n",
    "    return np.mean(ious)\n",
    "\n",
    "def color_to_one_hot_mask(mask, colors, height=IMG_HEIGHT, width=IMG_WIDTH):\n",
    "    \"\"\"Convert class indices to colored mask\"\"\"\n",
    "    color_mask = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    mask_np = mask.cpu().numpy() if torch.is_tensor(mask) else mask\n",
    "    \n",
    "    for c in range(len(colors)):\n",
    "        color_true = mask_np == c\n",
    "        for i in range(3):\n",
    "            color_mask[:, :, i] += color_true * colors[c][i]\n",
    "    \n",
    "    return color_mask\n",
    "\n",
    "# ========== TRAINING FUNCTION ==========\n",
    "def train_model(seed, save_dir):\n",
    "    print(f'\\n{\"=\"*50}')\n",
    "    print(f'STARTING TRAINING WITH SEED {seed}')\n",
    "    print(f'{\"=\"*50}')\n",
    "    \n",
    "    # Set seed\n",
    "    set_seed(seed)\n",
    "    \n",
    "    # Create save directory\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Get file lists\n",
    "    train_images_names = sorted([f for f in os.listdir(train_images_folder_path) if f.endswith('.png')])\n",
    "    train_mask_names = sorted([f for f in os.listdir(train_mask_folder_path) if f.endswith('.png')])\n",
    "    test_images_names = sorted([f for f in os.listdir(test_images_folder_path) if f.endswith('.png')])\n",
    "    test_mask_names = sorted([f for f in os.listdir(test_mask_folder_path) if f.endswith('.png')])\n",
    "    \n",
    "    # Split into train/val (300 for validation)\n",
    "    total_train = len(train_images_names)\n",
    "    val_indices = random.sample(range(total_train), 300)\n",
    "    train_indices = [i for i in range(total_train) if i not in val_indices]\n",
    "    \n",
    "    train_img_names = [train_images_names[i] for i in train_indices]\n",
    "    train_msk_names = [train_mask_names[i] for i in train_indices]\n",
    "    val_img_names = [train_images_names[i] for i in val_indices]\n",
    "    val_msk_names = [train_mask_names[i] for i in val_indices]\n",
    "    \n",
    "    print(f'Train samples: {len(train_img_names)}')\n",
    "    print(f'Val samples: {len(val_img_names)}')\n",
    "    print(f'Test samples: {len(test_images_names)}')\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = CityscapesDataset(\n",
    "        train_images_folder_path, train_mask_folder_path,\n",
    "        train_img_names, train_msk_names\n",
    "    )\n",
    "    \n",
    "    val_dataset = CityscapesDataset(\n",
    "        train_images_folder_path, train_mask_folder_path,\n",
    "        val_img_names, val_msk_names\n",
    "    )\n",
    "    \n",
    "    test_dataset = CityscapesDataset(\n",
    "        test_images_folder_path, test_mask_folder_path,\n",
    "        test_images_names, test_mask_names, is_train=False\n",
    "    )\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = UNetGDN(in_channels=3, num_classes=NUM_CLASSES).to(device)\n",
    "    print(f'\\nModel architecture:')\n",
    "    print(model)\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.L1Loss()  # MAE loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=15, verbose=True)\n",
    "    \n",
    "    # Training variables\n",
    "    best_iou = 0.0\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': [], 'val_iou': []}\n",
    "    \n",
    "    # Training loop\n",
    "    epochs = 300\n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} [Train]')\n",
    "        for images, masks in pbar:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            \n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            true_labels = torch.argmax(masks, dim=1)\n",
    "            correct = (preds == true_labels).sum().item()\n",
    "            \n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            train_correct += correct\n",
    "            train_total += true_labels.numel()\n",
    "            \n",
    "            pbar.set_postfix({'Loss': loss.item(), 'Acc': correct/true_labels.numel()})\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_acc = train_correct / train_total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        all_preds = []\n",
    "        all_masks = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                outputs = model(images)\n",
    "                \n",
    "                loss = criterion(outputs, masks)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                \n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                true_labels = torch.argmax(masks, dim=1)\n",
    "                correct = (preds == true_labels).sum().item()\n",
    "                \n",
    "                val_correct += correct\n",
    "                val_total += true_labels.numel()\n",
    "                \n",
    "                all_preds.append(preds.cpu())\n",
    "                all_masks.append(masks.cpu())\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_acc = val_correct / val_total\n",
    "        \n",
    "        # Calculate IoU\n",
    "        all_preds = torch.cat(all_preds, dim=0)\n",
    "        all_masks = torch.cat(all_masks, dim=0)\n",
    "        val_iou = iou_metrics(all_masks, all_preds)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_iou)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_iou > best_iou:\n",
    "            best_iou = val_iou\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_iou': val_iou,\n",
    "                'val_loss': val_loss,\n",
    "            }, os.path.join(save_dir, 'best_model.pth'))\n",
    "        \n",
    "        # Update history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_iou'].append(val_iou)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val IoU: {val_iou:.4f}')\n",
    "        \n",
    "        # Save checkpoint every 50 epochs\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'history': history,\n",
    "            }, os.path.join(save_dir, f'checkpoint_epoch_{epoch+1}.pth'))\n",
    "    \n",
    "    # Load best model for testing\n",
    "    checkpoint = torch.load(os.path.join(save_dir, 'best_model.pth'))\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Test phase\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    test_preds = []\n",
    "    test_masks = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in test_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            true_labels = torch.argmax(masks, dim=1)\n",
    "            correct = (preds == true_labels).sum().item()\n",
    "            \n",
    "            test_correct += correct\n",
    "            test_total += true_labels.numel()\n",
    "            \n",
    "            test_preds.append(preds.cpu())\n",
    "            test_masks.append(masks.cpu())\n",
    "    \n",
    "    test_acc = test_correct / test_total\n",
    "    test_preds = torch.cat(test_preds, dim=0)\n",
    "    test_masks = torch.cat(test_masks, dim=0)\n",
    "    test_iou = iou_metrics(test_masks, test_preds)\n",
    "    \n",
    "    print(f'\\nTest Results:')\n",
    "    print(f'Test Accuracy: {test_acc:.4f}')\n",
    "    print(f'Test IoU: {test_iou:.4f}')\n",
    "    print(f'Best Validation IoU: {best_iou:.4f}')\n",
    "    \n",
    "    # Save history\n",
    "    np.save(os.path.join(save_dir, 'history.npy'), history)\n",
    "    \n",
    "    # Plot training curves\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    axes[0, 0].plot(history['train_loss'], label='Train')\n",
    "    axes[0, 0].plot(history['val_loss'], label='Validation')\n",
    "    axes[0, 0].set_title('Model Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    axes[0, 1].plot(history['train_acc'], label='Train')\n",
    "    axes[0, 1].plot(history['val_acc'], label='Validation')\n",
    "    axes[0, 1].set_title('Model Accuracy')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    axes[1, 0].plot(history['val_iou'])\n",
    "    axes[1, 0].set_title('Validation IoU')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('IoU')\n",
    "    axes[1, 0].grid(True)\n",
    "    \n",
    "    # Visualize predictions\n",
    "    axes[1, 1].axis('off')\n",
    "    axes[1, 1].text(0.5, 0.5, f'Best Val IoU: {best_iou:.4f}\\nTest IoU: {test_iou:.4f}\\nTest Acc: {test_acc:.4f}',\n",
    "                   ha='center', va='center', fontsize=12, bbox=dict(boxstyle=\"round\", fc=\"w\"))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, 'training_curves.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Generate prediction visualization\n",
    "    visualize_predictions(model, test_dataset, colors, save_dir)\n",
    "    \n",
    "    return model, history, test_iou, test_acc\n",
    "\n",
    "def visualize_predictions(model, dataset, colors, save_dir, num_samples=5):\n",
    "    \"\"\"Visualize model predictions\"\"\"\n",
    "    model.eval()\n",
    "    indices = random.sample(range(len(dataset)), num_samples)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, num_samples*4))\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        image, mask = dataset[idx]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(image.unsqueeze(0).to(device))\n",
    "            pred = torch.argmax(output, dim=1).squeeze(0).cpu()\n",
    "        \n",
    "        # Original image\n",
    "        axes[i, 0].imshow(image.permute(1, 2, 0).numpy())\n",
    "        axes[i, 0].set_title('Original Image')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Ground truth mask\n",
    "        true_mask = torch.argmax(mask, dim=0)\n",
    "        colored_true = color_to_one_hot_mask(true_mask, colors)\n",
    "        axes[i, 1].imshow(colored_true)\n",
    "        axes[i, 1].set_title('Ground Truth')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # Predicted mask\n",
    "        colored_pred = color_to_one_hot_mask(pred, colors)\n",
    "        axes[i, 2].imshow(colored_pred)\n",
    "        axes[i, 2].set_title('Prediction')\n",
    "        axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, 'predictions.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# ========== MAIN EXECUTION ==========\n",
    "if __name__ == \"__main__\":\n",
    "    seeds = [0]  # You can add more seeds: [0, 11, 25, 333, 41, 55, 666, 70, 8, 123]\n",
    "    \n",
    "    results = []\n",
    "    for i, seed in enumerate(seeds):\n",
    "        save_dir = f'./Good_train/1_gdn/Train_{i}'\n",
    "        model, history, test_iou, test_acc = train_model(seed, save_dir)\n",
    "        \n",
    "        results.append({\n",
    "            'seed': seed,\n",
    "            'test_iou': test_iou,\n",
    "            'test_acc': test_acc,\n",
    "            'best_val_iou': max(history['val_iou'])\n",
    "        })\n",
    "    \n",
    "    # Print summary\n",
    "    print('\\n' + '='*50)\n",
    "    print('TRAINING SUMMARY')\n",
    "    print('='*50)\n",
    "    for res in results:\n",
    "        print(f\"Seed {res['seed']}: Test IoU: {res['test_iou']:.4f}, \"\n",
    "              f\"Test Acc: {res['test_acc']:.4f}, Best Val IoU: {res['best_val_iou']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
