{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f4d91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import jaccard_score\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6994e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15add6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define paths\n",
    "train_images_folder_path = \"/kaggle/input/cityscapes/train/img\"\n",
    "train_mask_folder_path = \"/kaggle/input/cityscapes/train/label\"\n",
    "test_images_folder_path = \"/kaggle/input/cityscapes/val/img\"\n",
    "test_mask_folder_path = \"/kaggle/input/cityscapes/val/label\"\n",
    "\n",
    "# Get image and mask names\n",
    "train_images_names_original = sorted([img for img in os.listdir(train_images_folder_path) if img.endswith('.png')])\n",
    "train_mask_names_original = sorted([img for img in os.listdir(train_mask_folder_path) if img.endswith('.png')])\n",
    "test_images_names = sorted([img for img in os.listdir(test_images_folder_path) if img.endswith('.png')])\n",
    "test_mask_names = sorted([img for img in os.listdir(test_mask_folder_path) if img.endswith('.png')])\n",
    "\n",
    "# Define colors for Cityscapes dataset\n",
    "names = ['unlabeled', 'dynamic', 'ground', 'road', 'sidewalk', 'parking', 'rail track', 'building', 'wall',\n",
    "         'fence', 'guard rail', 'bridge', 'tunnel', 'pole', 'traffic light', 'traffic sign', 'vegetation', 'terrain', 'sky', 'person', 'rider', 'car', 'truck',\n",
    "         'bus', 'caravan', 'trailer', 'train', 'motorcycle', 'bicycle', 'license plate']\n",
    "\n",
    "colors = np.array([(0, 0, 0), (111, 74, 0), (81, 0, 81), (128, 64, 128), (244, 35, 232), (250, 170, 160), (230, 150, 140), (70, 70, 70),\n",
    "        (102, 102, 156), (190, 153, 153), (180, 165, 180), (150, 100, 100), (150, 120, 90), (153, 153, 153), (250, 170, 30), (220, 220, 0), (107, 142, 35),\n",
    "        (152, 251, 152), (70, 130, 180), (220, 20, 60), (255, 0, 0), ( 0, 0, 142), ( 0, 0, 70), (0, 60, 100), (0, 0, 90), (0, 0, 110), (0, 80, 100), (0, 0, 230),\n",
    "        (119, 11, 32), (0, 0, 142)], dtype = np.int32)\n",
    "\n",
    "def one_hot_mask(y, colors_tensor):\n",
    "    \"\"\"Convert mask to one-hot encoding\"\"\"\n",
    "    batch_size, height, width, _ = y.shape\n",
    "    num_classes = len(colors)\n",
    "    one_hot = torch.zeros((batch_size, height, width, num_classes), device=y.device)\n",
    "    \n",
    "    for i, color in enumerate(colors_tensor):\n",
    "        class_map = torch.all(y == color.unsqueeze(0).unsqueeze(0).unsqueeze(0), dim=-1)\n",
    "        one_hot[..., i] = class_map.float()\n",
    "    \n",
    "    return one_hot\n",
    "\n",
    "class CityscapesDataset(Dataset):\n",
    "    def __init__(self, image_folder, mask_folder, image_names, mask_names, img_height=96, img_width=256, \n",
    "                 transform=None, one_hot=True):\n",
    "        self.image_folder = image_folder\n",
    "        self.mask_folder = mask_folder\n",
    "        self.image_names = image_names\n",
    "        self.mask_names = mask_names\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.transform = transform\n",
    "        self.one_hot = one_hot\n",
    "        \n",
    "        # Convert colors to tensor\n",
    "        self.colors_tensor = torch.tensor(colors, dtype=torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = os.path.join(self.image_folder, self.image_names[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = image.resize((self.img_width, self.img_height))\n",
    "        image = np.array(image).astype(np.float32) / 255.0\n",
    "        image = torch.tensor(image).permute(2, 0, 1)  # C, H, W\n",
    "        \n",
    "        # Load mask\n",
    "        mask_path = os.path.join(self.mask_folder, self.mask_names[idx])\n",
    "        mask = Image.open(mask_path).convert('RGB')\n",
    "        mask = mask.resize((self.img_width, self.img_height), Image.NEAREST)\n",
    "        mask = np.array(mask).astype(np.int32)\n",
    "        mask = torch.tensor(mask)  # H, W, C\n",
    "        \n",
    "        if self.one_hot:\n",
    "            # One-hot encoding\n",
    "            mask_one_hot = torch.zeros((self.img_height, self.img_width, len(colors)))\n",
    "            for i, color in enumerate(colors):\n",
    "                class_map = torch.all(mask == torch.tensor(color), dim=-1)\n",
    "                mask_one_hot[:, :, i] = class_map.float()\n",
    "            mask = mask_one_hot.permute(2, 0, 1)  # C, H, W\n",
    "        else:\n",
    "            mask = mask.permute(2, 0, 1)  # C, H, W\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, mask\n",
    "\n",
    "# GDN Layer\n",
    "class NonNegConstraint:\n",
    "    def __call__(self, module):\n",
    "        if hasattr(module, 'weight'):\n",
    "            module.weight.data = torch.clamp(module.weight.data, min=1e-15)\n",
    "\n",
    "class GDN(nn.Module):\n",
    "    def __init__(self, in_channels, filter_size=3):\n",
    "        super(GDN, self).__init__()\n",
    "        self.filter_size = filter_size\n",
    "        self.padding = (filter_size - 1) // 2\n",
    "        \n",
    "        # Learnable parameters\n",
    "        self.beta = nn.Parameter(torch.ones(in_channels))\n",
    "        self.alpha = nn.Parameter(torch.ones(in_channels), requires_grad=False)\n",
    "        self.epsilon = nn.Parameter(torch.ones(in_channels), requires_grad=False)\n",
    "        \n",
    "        # Gamma weights\n",
    "        self.gamma = nn.Parameter(torch.zeros(filter_size, filter_size, in_channels, in_channels))\n",
    "        \n",
    "        # Apply non-negative constraint\n",
    "        self.apply_constraint = NonNegConstraint()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply constraints\n",
    "        self.apply_constraint(self)\n",
    "        \n",
    "        # Input shape: (B, C, H, W)\n",
    "        abs_x = torch.abs(x)\n",
    "        abs_x_alpha = torch.pow(abs_x, self.alpha.view(1, -1, 1, 1))\n",
    "        \n",
    "        # Convolution for normalization term\n",
    "        norm_conv = F.conv2d(\n",
    "            abs_x_alpha,\n",
    "            self.gamma.permute(3, 2, 0, 1),  # (out_c, in_c, H, W)\n",
    "            padding=self.padding,\n",
    "            groups=x.shape[1]  # Depthwise convolution\n",
    "        )\n",
    "        \n",
    "        norm_term = self.beta.view(1, -1, 1, 1) + norm_conv\n",
    "        norm_term = torch.pow(norm_term, self.epsilon.view(1, -1, 1, 1))\n",
    "        \n",
    "        return x / norm_term\n",
    "\n",
    "# UNet Model\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout_rate=0.2):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.dropout = nn.Dropout2d(dropout_rate)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class UNetWithGDN(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=30):\n",
    "        super(UNetWithGDN, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.gdn = GDN(in_channels)\n",
    "        self.encoder1 = ConvBlock(in_channels, 16)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.encoder2 = ConvBlock(16, 32)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.encoder3 = ConvBlock(32, 64)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.encoder4 = ConvBlock(64, 128)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Bridge\n",
    "        self.bridge = ConvBlock(128, 256)\n",
    "        \n",
    "        # Decoder\n",
    "        self.upconv4 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.decoder4 = ConvBlock(256, 128)  # 128 from upconv + 128 from encoder4\n",
    "        \n",
    "        self.upconv3 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.decoder3 = ConvBlock(128, 64)  # 64 from upconv + 64 from encoder3\n",
    "        \n",
    "        self.upconv2 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
    "        self.decoder2 = ConvBlock(64, 32)  # 32 from upconv + 32 from encoder2\n",
    "        \n",
    "        self.upconv1 = nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2)\n",
    "        self.decoder1 = ConvBlock(32, 16)  # 16 from upconv + 16 from encoder1\n",
    "        \n",
    "        # Output\n",
    "        self.output = nn.Conv2d(16, num_classes, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        g1 = self.gdn(x)\n",
    "        x1 = self.encoder1(g1)\n",
    "        p1 = self.pool1(x1)\n",
    "        \n",
    "        x2 = self.encoder2(p1)\n",
    "        p2 = self.pool2(x2)\n",
    "        \n",
    "        x3 = self.encoder3(p2)\n",
    "        p3 = self.pool3(x3)\n",
    "        \n",
    "        x4 = self.encoder4(p3)\n",
    "        p4 = self.pool4(x4)\n",
    "        \n",
    "        # Bridge\n",
    "        b1 = self.bridge(p4)\n",
    "        \n",
    "        # Decoder\n",
    "        u4 = self.upconv4(b1)\n",
    "        u4 = torch.cat([u4, x4], dim=1)\n",
    "        d4 = self.decoder4(u4)\n",
    "        \n",
    "        u3 = self.upconv3(d4)\n",
    "        u3 = torch.cat([u3, x3], dim=1)\n",
    "        d3 = self.decoder3(u3)\n",
    "        \n",
    "        u2 = self.upconv2(d3)\n",
    "        u2 = torch.cat([u2, x2], dim=1)\n",
    "        d2 = self.decoder2(u2)\n",
    "        \n",
    "        u1 = self.upconv1(d2)\n",
    "        u1 = torch.cat([u1, x1], dim=1)\n",
    "        d1 = self.decoder1(u1)\n",
    "        \n",
    "        # Output\n",
    "        output = self.output(d1)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Metrics and visualization functions\n",
    "def iou_metrics(y_true, y_pred, num_classes=30):\n",
    "    \"\"\"Calculate mean IoU\"\"\"\n",
    "    batch_size = y_true.shape[0]\n",
    "    ious = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        # Convert to numpy for sklearn\n",
    "        true_flat = y_true[i].cpu().numpy().reshape(-1, num_classes)\n",
    "        pred_flat = y_pred[i].cpu().numpy().reshape(-1, num_classes)\n",
    "        \n",
    "        iou = jaccard_score(true_flat, pred_flat, average='samples', zero_division=0)\n",
    "        ious.append(iou)\n",
    "    \n",
    "    return np.mean(ious)\n",
    "\n",
    "def color_to_one_hot_mask(mask, colors_tensor, img_height=96, img_width=256):\n",
    "    \"\"\"Convert class indices to color mask\"\"\"\n",
    "    color_mask = np.zeros((img_height, img_width, 3), dtype=np.float32)\n",
    "    \n",
    "    for c in range(len(colors)):\n",
    "        color_true = (mask == c)\n",
    "        for i in range(3):\n",
    "            color_mask[:, :, i] += color_true * colors[c][i]\n",
    "    \n",
    "    return color_mask.astype(np.uint8)\n",
    "\n",
    "# Training function\n",
    "def train_model(seed=0):\n",
    "    print(f'STARTS TRAINING NUMBER {seed}')\n",
    "    \n",
    "    # Set seeds\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    # Split data\n",
    "    all_indices = list(range(len(train_images_names_original)))\n",
    "    val_indices = random.sample(all_indices, 300)\n",
    "    train_indices = list(set(all_indices) - set(val_indices))\n",
    "    \n",
    "    train_image_names = [train_images_names_original[i] for i in train_indices]\n",
    "    train_mask_names = [train_mask_names_original[i] for i in train_indices]\n",
    "    val_image_names = [train_images_names_original[i] for i in val_indices]\n",
    "    val_mask_names = [train_mask_names_original[i] for i in val_indices]\n",
    "    \n",
    "    print(f'Train images: {len(train_image_names)}')\n",
    "    print(f'Val images: {len(val_image_names)}')\n",
    "    print(f'Test images: {len(test_images_names)}')\n",
    "    \n",
    "    # Create datasets\n",
    "    img_height, img_width = 96, 256\n",
    "    batch_size = 32\n",
    "    \n",
    "    train_dataset = CityscapesDataset(\n",
    "        train_images_folder_path, train_mask_folder_path,\n",
    "        train_image_names, train_mask_names,\n",
    "        img_height, img_width\n",
    "    )\n",
    "    \n",
    "    val_dataset = CityscapesDataset(\n",
    "        train_images_folder_path, train_mask_folder_path,\n",
    "        val_image_names, val_mask_names,\n",
    "        img_height, img_width\n",
    "    )\n",
    "    \n",
    "    test_dataset = CityscapesDataset(\n",
    "        test_images_folder_path, test_mask_folder_path,\n",
    "        test_images_names, test_mask_names,\n",
    "        img_height, img_width\n",
    "    )\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = UNetWithGDN(in_channels=3, num_classes=30).to(device)\n",
    "    print(model)\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.L1Loss()  # MAE loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=15, min_lr=1e-12)\n",
    "    \n",
    "    # Training metrics storage\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'val_iou': []}\n",
    "    best_iou = 0.0\n",
    "    ious = []\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = f'./Good_train/1_gdn/Train_{seed}'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Training loop\n",
    "    epochs = 300\n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for images, masks in train_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            with torch.no_grad():\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                true_classes = torch.argmax(masks, dim=1)\n",
    "                correct = (preds == true_classes).sum().item()\n",
    "                train_correct += correct\n",
    "                train_total += true_classes.numel()\n",
    "            \n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        all_preds = []\n",
    "        all_true = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                outputs = model(images)\n",
    "                \n",
    "                loss = criterion(outputs, masks)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                true_classes = torch.argmax(masks, dim=1)\n",
    "                \n",
    "                correct = (preds == true_classes).sum().item()\n",
    "                val_correct += correct\n",
    "                val_total += true_classes.numel()\n",
    "                \n",
    "                all_preds.append(preds.cpu())\n",
    "                all_true.append(true_classes.cpu())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_acc = train_correct / train_total\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "        \n",
    "        # Calculate IoU\n",
    "        val_preds = torch.cat(all_preds, dim=0)\n",
    "        val_true = torch.cat(all_true, dim=0)\n",
    "        \n",
    "        # Convert to one-hot for IoU calculation\n",
    "        val_true_one_hot = F.one_hot(val_true, num_classes=30).float()\n",
    "        val_preds_one_hot = F.one_hot(val_preds, num_classes=30).float()\n",
    "        \n",
    "        iou = iou_metrics(val_true_one_hot, val_preds_one_hot)\n",
    "        ious.append(iou)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(iou)\n",
    "        \n",
    "        # Save best model\n",
    "        if iou > best_iou:\n",
    "            best_iou = iou\n",
    "            torch.save(model.state_dict(), os.path.join(output_dir, 'best_model.pth'))\n",
    "        \n",
    "        # Store history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_iou'].append(iou)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}:')\n",
    "        print(f'  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "        print(f'  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val IoU: {iou:.4f}')\n",
    "        print(f'  Best IoU: {best_iou:.4f}')\n",
    "    \n",
    "    # Save history\n",
    "    np.save(os.path.join(output_dir, 'history.npy'), history)\n",
    "    np.save(os.path.join(output_dir, 'ious.npy'), np.array(ious))\n",
    "    \n",
    "    # Plot training curves\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(history['train_acc'], label='Train')\n",
    "    plt.plot(history['val_acc'], label='Validation')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(history['train_loss'], label='Train')\n",
    "    plt.plot(history['val_loss'], label='Validation')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(history['val_iou'])\n",
    "    plt.title('Validation IoU')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('IoU')\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'training_curves.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Load best model for evaluation\n",
    "    model.load_state_dict(torch.load(os.path.join(output_dir, 'best_model.pth')))\n",
    "    model.eval()\n",
    "    \n",
    "    # Test evaluation\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    all_test_preds = []\n",
    "    all_test_true = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in test_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            true_classes = torch.argmax(masks, dim=1)\n",
    "            \n",
    "            correct = (preds == true_classes).sum().item()\n",
    "            test_correct += correct\n",
    "            test_total += true_classes.numel()\n",
    "            \n",
    "            all_test_preds.append(preds.cpu())\n",
    "            all_test_true.append(true_classes.cpu())\n",
    "    \n",
    "    test_acc = test_correct / test_total\n",
    "    test_preds = torch.cat(all_test_preds, dim=0)\n",
    "    test_true = torch.cat(all_test_true, dim=0)\n",
    "    \n",
    "    # Calculate test IoU\n",
    "    test_true_one_hot = F.one_hot(test_true, num_classes=30).float()\n",
    "    test_preds_one_hot = F.one_hot(test_preds, num_classes=30).float()\n",
    "    test_iou = iou_metrics(test_true_one_hot, test_preds_one_hot)\n",
    "    \n",
    "    print(f'\\nTest Results:')\n",
    "    print(f'  Test Accuracy: {test_acc:.4f}')\n",
    "    print(f'  Test IoU: {test_iou:.4f}')\n",
    "    print(f'  Best Validation IoU: {best_iou:.4f}')\n",
    "    \n",
    "    # Visualization\n",
    "    visualize_predictions(model, test_dataset, colors, output_dir, img_height, img_width)\n",
    "    \n",
    "    return model, history, best_iou\n",
    "\n",
    "def visualize_predictions(model, dataset, colors, output_dir, img_height=96, img_width=256, num_samples=5):\n",
    "    \"\"\"Visualize predictions on sample images\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get random indices\n",
    "    indices = random.sample(range(len(dataset)), num_samples)\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        image, mask = dataset[idx]\n",
    "        \n",
    "        # Add batch dimension\n",
    "        image_batch = image.unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(image_batch)\n",
    "            pred = torch.argmax(output, dim=1).squeeze().cpu().numpy()\n",
    "        \n",
    "        # Get ground truth\n",
    "        true_mask = torch.argmax(mask, dim=0).cpu().numpy()\n",
    "        \n",
    "        # Convert to color\n",
    "        pred_color = color_to_one_hot_mask(pred, colors, img_height, img_width)\n",
    "        true_color = color_to_one_hot_mask(true_mask, colors, img_height, img_width)\n",
    "        \n",
    "        # Plot\n",
    "        plt.subplot(3, num_samples, i + 1)\n",
    "        plt.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "        plt.title('Image')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(3, num_samples, i + 1 + num_samples)\n",
    "        plt.imshow(true_color)\n",
    "        plt.title('Ground Truth')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(3, num_samples, i + 1 + 2 * num_samples)\n",
    "        plt.imshow(pred_color)\n",
    "        plt.title('Prediction')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'predictions.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Main training loop\n",
    "seeds = [0]\n",
    "\n",
    "for seed in seeds:\n",
    "    model, history, best_iou = train_model(seed)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
